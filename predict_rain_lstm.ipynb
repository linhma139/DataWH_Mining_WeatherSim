{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2620207-a467-4533-b825-341ca074e24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df = spark.read.table(\"hcmut.gold.fact_vn_weather_daily\")\n",
    "selected_columns = [\n",
    "    \"dt_date_record\",\n",
    "    \"ds_location\",\n",
    "    \"nr_temperature_2m_mean\",\n",
    "    \"nr_relative_humidity_2m_mean\",\n",
    "    \"nr_precipitation_sum\",\n",
    "    \"nr_pressure_msl_mean\",\n",
    "    \"nr_cloud_cover_mean\",\n",
    "    \"nr_sunshine_duration\",\n",
    "    \"nr_wind_speed_10m_mean\",\n",
    "    \"nr_soil_moisture_0_to_7cm_mean\",\n",
    "    \"nr_weather_code\"\n",
    "]\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"loc_hcm\",\n",
    "    when(col(\"ds_location\") == \"Ho Chi Minh City\", 1).otherwise(0)\n",
    ").withColumn(\n",
    "    \"loc_dn\",\n",
    "    when(col(\"ds_location\") == \"Da Nang City\", 1).otherwise(0)\n",
    ").withColumn(\n",
    "    \"loc_hn\",\n",
    "    when(col(\"ds_location\") == \"Ha Noi City\", 1).otherwise(0)\n",
    ")\n",
    "selected_columns.extend([\"loc_hcm\", \"loc_dn\", \"loc_hn\"])\n",
    "\n",
    "df = (\n",
    "    df.select(*selected_columns)\n",
    "      .dropna()\n",
    "      .dropDuplicates([\"dt_date_record\"])\n",
    "      .orderBy(\"dt_date_record\")\n",
    ")\n",
    "\n",
    "pdf = df.toPandas().sort_values(\"dt_date_record\")\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "\n",
    "rain_codes = [51,53,55,61,63,65]\n",
    "pdf[\"rain_label\"] = pdf[\"nr_weather_code\"].apply(lambda x: 1 if x in rain_codes else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d764bf1a-d8cf-4bba-8ba6-317301ac6314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numeric_cols = [\n",
    "    \"nr_temperature_2m_mean\",\n",
    "    \"nr_relative_humidity_2m_mean\",\n",
    "    \"nr_precipitation_sum\",\n",
    "    \"nr_pressure_msl_mean\",\n",
    "    \"nr_cloud_cover_mean\",\n",
    "    \"nr_sunshine_duration\",\n",
    "    \"nr_wind_speed_10m_mean\",\n",
    "    \"nr_soil_moisture_0_to_7cm_mean\"\n",
    "]\n",
    "\n",
    "location_cols = [\"loc_hcm\", \"loc_dn\", \"loc_hn\"]\n",
    "\n",
    "lag_dfs = []\n",
    "for lag in range(1, 25):\n",
    "    lag_df = pdf[numeric_cols].shift(lag)\n",
    "    lag_df.columns = [f\"{c}_lag_{lag}\" for c in numeric_cols]\n",
    "    lag_dfs.append(lag_df)\n",
    "\n",
    "pdf = pd.concat([pdf] + lag_dfs, axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "feature_cols = [c for c in pdf.columns if any(x in c for x in numeric_cols)] + location_cols\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(pdf[[c for c in feature_cols if c not in location_cols]])\n",
    "X_scaled = np.hstack([X_numeric_scaled, pdf[location_cols].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "807be862-891b-49f4-ae75-dcedd372bb91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "X_list = []\n",
    "for i in range(seq_len, len(X_scaled)):\n",
    "    X_list.append(X_scaled[i-seq_len:i])\n",
    "\n",
    "X = np.array(X_list)\n",
    "y = pdf[\"rain_label\"].values[seq_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8132be6-17ab-40b0-928f-e98d4aae3ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d40239-d86e-40f5-9133-4a9718bc2e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=False, input_shape=(seq_len, X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# --- THAY ĐỔI 1: TÍNH TOÁN CLASS WEIGHT ---\n",
    "# Đếm số lượng 0 và 1\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# y_train phải được định nghĩa từ cell trước\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(zip(np.unique(y_train), weights))\n",
    "\n",
    "print(f\"Sử dụng Class Weights (để phạt nặng hơn việc đoán sai Lớp 0): {class_weights_dict}\")\n",
    "# Ví dụ output: {0: 2.55, 1: 0.62}\n",
    "\n",
    "# --- THAY ĐỔI 2: THÊM `class_weight` VÀ TĂNG `batch_size` ---\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,  \n",
    "    validation_split=0.1,\n",
    "    callbacks=[es],\n",
    "    class_weight=class_weights_dict, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83152ddf-83f5-4748-88df-e4f1c636e7f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc12ed27-9218-4d6a-9ef0-ebbe938c12eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reconstructing the confusion matrix from the user's classification report\n",
    "# Report:\n",
    "#                precision    recall  f1-score   support\n",
    "#            0       0.54      0.73      0.62        83\n",
    "#            1       0.93      0.84      0.88       341\n",
    "\n",
    "# Total samples\n",
    "total_actual_0 = 83\n",
    "total_actual_1 = 341\n",
    "\n",
    "# From Recall\n",
    "# True Negative (TN) = Recall_0 * Total_Actual_0\n",
    "tn = round(0.73 * total_actual_0) # 60.59 -> 61\n",
    "# True Positive (TP) = Recall_1 * Total_Actual_1\n",
    "tp = round(0.84 * total_actual_1) # 286.44 -> 286\n",
    "\n",
    "# From totals\n",
    "# False Positive (FP) = Total_Actual_0 - TN\n",
    "fp = total_actual_0 - tn # 83 - 61 = 22\n",
    "# False Negative (FN) = Total_Actual_1 - TP\n",
    "fn = total_actual_1 - tp # 341 - 286 = 55\n",
    "\n",
    "# Create the matrix\n",
    "cm_data = [[tn, fp],\n",
    "           [fn, tp]]\n",
    "\n",
    "cm_df = pd.DataFrame(cm_data,\n",
    "                     index = ['Actual 0 (No Rain)', 'Actual 1 (Rain)'], \n",
    "                     columns = ['Predicted 0 (No Rain)', 'Predicted 1 (Rain)'])\n",
    "\n",
    "display(cm_df)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Rain Prediction (Improved Model)')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plot_filename = 'confusion_matrix_rain_improved.png'\n",
    "plt.savefig(plot_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b388199b-0f42-4c11-ba6a-5f09e9749e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lấy 30 ngày cuối\n",
    "last_1000 = pdf.tail(1000)\n",
    "\n",
    "# Mốc thời gian cách 5 ngày 1 lần\n",
    "xticks = last_1000[\"dt_date_record\"].iloc[::30]\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "# Vẽ dạng cột: có cột nếu rain_label = 1\n",
    "plt.bar(last_1000[\"dt_date_record\"], last_1000[\"rain_label\"])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Rain (1 = Rain)\")\n",
    "plt.title(\"Rain Label - Last 1000 Days (Bar Plot)\")\n",
    "plt.xticks(xticks, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df74553f-e5b6-4285-8565-9572bc2c9573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- LOGGING DỰ ĐOÁN MƯA (VỚI SIGNATURE) ---\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 7.1. Lấy các biến đã huấn luyện từ các cell trước ---\n",
    "# (Đảm bảo các biến này đã tồn tại sau khi huấn luyện)\n",
    "\n",
    "try:\n",
    "    trained_model = model   # Model đã fit (đã tinh chỉnh)\n",
    "    trained_scaler = scaler # Scaler đã fit\n",
    "\n",
    "    # Lấy các cột numeric đã được lag\n",
    "    numeric_feature_cols = [c for c in feature_cols if c not in location_cols]\n",
    "    \n",
    "    print(\"Đã xác định các biến huấn luyện (model, scaler, pdf, etc.).\")\n",
    "    print(f\"Sequence length: {seq_len}\")\n",
    "    print(f\"Total features: {len(feature_cols)}\")\n",
    "    print(f\"Numeric/Lagged features: {len(numeric_feature_cols)}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"LỖI: Không tìm thấy biến cần thiết. Bạn đã chạy cell huấn luyện chưa?\")\n",
    "    print(f\"Chi tiết: {e}\")\n",
    "    # dbutils.notebook.exit(\"Biến huấn luyện không tồn tại\")\n",
    "\n",
    "\n",
    "# --- 7.2. Định nghĩa Lớp Wrapper (xử lý \"scale một phần\") ---\n",
    "\n",
    "class RainPredictionWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self, model, scaler, seq_len, \n",
    "                 feature_columns, numeric_feature_cols, location_cols):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.feature_columns = feature_columns\n",
    "        self.numeric_feature_cols = numeric_feature_cols\n",
    "        self.location_cols = location_cols\n",
    "        \n",
    "        self.n_features = len(self.feature_columns)\n",
    "\n",
    "    def _preprocess(self, model_input_df):\n",
    "        # 'model_input_df' là một Pandas DF (seq_len, n_total_features)\n",
    "        \n",
    "        # 1. Tách riêng 2 nhóm cột (giống hệt lúc training)\n",
    "        numeric_data = model_input_df[self.numeric_feature_cols]\n",
    "        location_data = model_input_df[self.location_cols].values\n",
    "        \n",
    "        # 2. CHỈ scale các cột numeric (đã được lag)\n",
    "        scaled_numeric = self.scaler.transform(numeric_data)\n",
    "        \n",
    "        # 3. Kết hợp lại\n",
    "        scaled_data = np.hstack([scaled_numeric, location_data])\n",
    "        \n",
    "        # 4. Reshape cho LSTM [samples, timesteps, features]\n",
    "        # Input là (3, 203) -> Reshape thành (1, 3, 203)\n",
    "        input_sequence = scaled_data.reshape(1, self.seq_len, self.n_features)\n",
    "        return input_sequence\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # 'model_input' là một Pandas DataFrame của (seq_len, n_total_features)\n",
    "        \n",
    "        if model_input.shape[0] != self.seq_len:\n",
    "            raise ValueError(f\"Input data must have exactly {self.seq_len} rows (timesteps).\")\n",
    "            \n",
    "        # Bước 1-4: Tiền xử lý (Tách, Scale, Hstack, Reshape)\n",
    "        input_sequence = self._preprocess(model_input)\n",
    "        \n",
    "        # Bước 5: Dự đoán (Model trả về xác suất)\n",
    "        prediction_prob = self.model.predict(input_sequence) # Shape (1, 1)\n",
    "        \n",
    "        # Bước 6: Hậu xử lý\n",
    "        prob = float(prediction_prob[0][0])\n",
    "        label = 1 if prob > 0.5 else 0\n",
    "        \n",
    "        # Trả về một DataFrame (yêu cầu của MLflow)\n",
    "        return pd.DataFrame({\n",
    "            \"prediction_label\": [label],\n",
    "            \"prediction_probability\": [prob]\n",
    "        })\n",
    "\n",
    "print(\"Đã định nghĩa lớp 'RainPredictionWrapper'.\")\n",
    "\n",
    "# --- 7.3. Tạo Signature và Logging vào Unity Catalog ---\n",
    "\n",
    "print(\"Đang tạo đối tượng wrapper...\")\n",
    "pyfunc_wrapper = RainPredictionWrapper(\n",
    "    model=trained_model,\n",
    "    scaler=trained_scaler,\n",
    "    seq_len=seq_len,\n",
    "    feature_columns=feature_cols,\n",
    "    numeric_feature_cols=numeric_feature_cols,\n",
    "    location_cols=location_cols\n",
    ")\n",
    "\n",
    "print(\"Đang chuẩn bị dữ liệu mẫu cho signature...\")\n",
    "try:\n",
    "    # Lấy một mẫu input (ví dụ: seq_len hàng đầu tiên từ 'pdf')\n",
    "    input_example = pdf[feature_cols].iloc[0:seq_len]\n",
    "    \n",
    "    if input_example.shape[0] != seq_len:\n",
    "        raise ValueError(f\"Dữ liệu 'pdf' không đủ {seq_len} dòng để làm mẫu.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"LỖI: Không tìm thấy 'pdf'. Bạn phải chạy lại cell training để có 'pdf'.\")\n",
    "    # dbutils.notebook.exit(\"Cần 'pdf' để tạo signature\")\n",
    "\n",
    "print(f\"Đang chạy dự đoán mẫu trên {input_example.shape[0]} dòng...\")\n",
    "output_example = pyfunc_wrapper.predict(context=None, model_input=input_example)\n",
    "\n",
    "print(\"Đang suy ra signature từ input và output mẫu...\")\n",
    "signature = infer_signature(input_example, output_example)\n",
    "print(\"--- Đã tạo signature thành công ---\")\n",
    "\n",
    "\n",
    "# 3. LOG VÀ ĐĂNG KÝ MÔ HÌNH (VỚI SIGNATURE)\n",
    "\n",
    "# !!! QUAN TRỌNG: Sửa lại <CATALOG_NAME> và <SCHEMA_NAME> của bạn\n",
    "UC_CATALOG_NAME = \"hcmut\"  # !!! THAY THẾ: Bằng Catalog của bạn\n",
    "UC_SCHEMA_NAME = \"gold\"    # !!! THAY THẾ: Bằng Schema của bạn (ví dụ: 'gold' hoặc 'ml')\n",
    "MODEL_NAME = \"weatherforecast_rain_lstm\" # Tên mô hình dự đoán mưa\n",
    "model_registry_name = f\"{UC_CATALOG_NAME}.{UC_SCHEMA_NAME}.{MODEL_NAME}\"\n",
    "\n",
    "# Set Model Registry về UC\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Đặt experiment\n",
    "experiment_name = f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/LSTM_Rain_Forecast\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Bắt đầu logging vào Experiment: {experiment_name}\")\n",
    "print(f\"Đăng ký mô hình UC với tên: {model_registry_name}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LSTM_Rain_Forecast_UC_Run\") as run:\n",
    "    \n",
    "    mlflow.log_param(\"seq_len\", seq_len)\n",
    "    mlflow.log_param(\"feature_columns_count\", len(feature_cols))\n",
    "\n",
    "    # Log các chỉ số (từ cell đánh giá cuối)\n",
    "    if 'y_test' in locals():\n",
    "        from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        mlflow.log_metric(\"recall_class_0\", recall_score(y_test, y_pred, pos_label=0))\n",
    "        mlflow.log_metric(\"recall_class_1\", recall_score(y_test, y_pred, pos_label=1))\n",
    "        mlflow.log_metric(\"macro_f1\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(\"Đang log mô hình với signature...\")\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=pyfunc_wrapper,\n",
    "        registered_model_name=model_registry_name,\n",
    "        signature=signature\n",
    "    )\n",
    "    \n",
    "    print(f\"--- HOÀN TẤT LOGGING (với Signature) ---\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Đã đăng ký phiên bản mới cho mô hình: '{model_registry_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "673698a6-7f8e-4023-a0ef-d3433ab649d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---  PIPELINE DỰ BÁO MƯA HÀNG NGÀY ---\n",
    "# Code này đã bao gồm TẤT CẢ các import, class, và logic\n",
    "\n",
    "# === CELL 1: IMPORTS ===\n",
    "import mlflow\n",
    "import mlflow.pyfunc  # Quan trọng, phải import trước khi định nghĩa class\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, when\n",
    "import datetime\n",
    "\n",
    "# === CELL 2: ĐỊNH NGHĨA CLASS (PHẢI CÓ) ===\n",
    "# (Class này phải được định nghĩa để mlflow.load_model() hoạt động)\n",
    "\n",
    "class RainPredictionWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self, model, scaler, seq_len, \n",
    "                 feature_columns, numeric_feature_cols, location_cols):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.seq_len = seq_len\n",
    "        self.feature_columns = feature_columns\n",
    "        self.numeric_feature_cols = numeric_feature_cols\n",
    "        self.location_cols = location_cols\n",
    "        self.n_features = len(self.feature_columns)\n",
    "\n",
    "    def _preprocess(self, model_input_df):\n",
    "        # 1. Tách riêng 2 nhóm cột (giống hệt lúc training)\n",
    "        numeric_data = model_input_df[self.numeric_feature_cols]\n",
    "        location_data = model_input_df[self.location_cols].values\n",
    "        \n",
    "        # 2. CHỈ scale các cột numeric (đã được lag)\n",
    "        scaled_numeric = self.scaler.transform(numeric_data)\n",
    "        \n",
    "        # 3. Kết hợp lại\n",
    "        scaled_data = np.hstack([scaled_numeric, location_data])\n",
    "        \n",
    "        # 4. Reshape cho LSTM [samples, timesteps, features]\n",
    "        input_sequence = scaled_data.reshape(1, self.seq_len, self.n_features)\n",
    "        return input_sequence\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        if model_input.shape[0] != self.seq_len:\n",
    "            raise ValueError(f\"Input data must have exactly {self.seq_len} rows (timesteps).\")\n",
    "            \n",
    "        input_sequence = self._preprocess(model_input)\n",
    "        prediction_prob = self.model.predict(input_sequence) # Shape (1, 1)\n",
    "        \n",
    "        prob = float(prediction_prob[0][0])\n",
    "        label = 1 if prob > 0.5 else 0\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"prediction_label\": [label],\n",
    "            \"prediction_probability\": [prob]\n",
    "        })\n",
    "\n",
    "print(\"--- Cell 1 & 2: Imports và Class Definition đã sẵn sàng ---\")\n",
    "\n",
    "\n",
    "# === CELL 3: THIẾT LẬP CẤU HÌNH PIPELINE ===\n",
    "print(\"\\n--- Cell 3: Thiết lập Cấu hình Pipeline ---\")\n",
    "\n",
    "# !!! QUAN TRỌNG: Sửa lại <CATALOG_NAME> và <SCHEMA_NAME> của bạn\n",
    "UC_CATALOG_NAME = \"hcmut\"\n",
    "UC_SCHEMA_NAME = \"gold\"\n",
    "# (Đảm bảo tên này viết thường khớp với Bước 7)\n",
    "MODEL_NAME = \"weatherforecast_rain_lstm\" \n",
    "# (Đảm bảo alias này khớp với bạn đã đặt trong UI)\n",
    "MODEL_ALIAS = \"rain\"                   \n",
    "MODEL_REGISTRY_NAME = f\"{UC_CATALOG_NAME}.{UC_SCHEMA_NAME}.{MODEL_NAME}\"\n",
    "\n",
    "SOURCE_TABLE = \"hcmut.gold.fact_vn_weather_daily\" \n",
    "TARGET_TABLE = \"hcmut.gold.lstm_rain_daily\"\n",
    "\n",
    "CITIES_TO_FORECAST = [\"Ho Chi Minh City\", \"Da Nang City\", \"Ha Noi City\"]\n",
    "CITY_LOC_COLS = {\"Ho Chi Minh City\": \"loc_hcm\", \"Da Nang City\": \"loc_dn\", \"Ha Noi City\": \"loc_hn\"}\n",
    "\n",
    "N_LAG_DAYS = 24 \n",
    "SEQ_LEN = 3     \n",
    "\n",
    "numeric_cols = [\n",
    "    \"nr_temperature_2m_mean\", \"nr_relative_humidity_2m_mean\", \"nr_precipitation_sum\",\n",
    "    \"nr_pressure_msl_mean\", \"nr_cloud_cover_mean\", \"nr_sunshine_duration\",\n",
    "    \"nr_wind_speed_10m_mean\", \"nr_soil_moisture_0_to_7cm_mean\"\n",
    "]\n",
    "location_cols = [\"loc_hcm\", \"loc_dn\", \"loc_hn\"]\n",
    "BASE_COLUMNS_TO_SELECT = [\"dt_date_record\", \"ds_location\"] + numeric_cols\n",
    "\n",
    "# === CELL 4: TẢI MÔ HÌNH (PHỤ THUỘC CELL 1 & 2) ===\n",
    "print(\"\\n--- Cell 4: Tải Mô hình từ Registry ---\")\n",
    "\n",
    "# (FIX 1) Đặt registry về UC để chạy độc lập\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "print(f\"Đang tải mô hình '{MODEL_REGISTRY_NAME}' với bí danh (alias) '@{MODEL_ALIAS}'...\")\n",
    "model_uri = f\"models:/{MODEL_REGISTRY_NAME}@{MODEL_ALIAS}\"\n",
    "\n",
    "try:\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    print(\"--- Tải mô hình thành công ---\")\n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Không thể tải mô hình. Tên model hoặc alias không đúng.\")\n",
    "    print(f\"Model: {MODEL_REGISTRY_NAME}, Alias: @{MODEL_ALIAS}\")\n",
    "    print(f\"Chi tiết lỗi: {e}\")\n",
    "    dbutils.notebook.exit(f\"Model loading failed. Check alias '@{MODEL_ALIAS}'.\")\n",
    "\n",
    "# === CELL 5: LẤY DỮ LIỆU VÀ FEATURE ENGINEERING ===\n",
    "print(\"\\n--- Cell 5: Lấy dữ liệu và Feature Engineering ---\")\n",
    "\n",
    "days_to_fetch = N_LAG_DAYS + SEQ_LEN + 10 \n",
    "\n",
    "print(f\"Đang lấy {days_to_fetch} ngày dữ liệu mới nhất từ {SOURCE_TABLE}...\")\n",
    "pdf = (\n",
    "    spark.read.table(SOURCE_TABLE)\n",
    "    .select(*BASE_COLUMNS_TO_SELECT)\n",
    "    .orderBy(col(\"dt_date_record\").desc())\n",
    "    .limit(days_to_fetch * 3) # (3 thành phố)\n",
    "    .orderBy(col(\"dt_date_record\").asc())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "# 1. Tái tạo One-Hot\n",
    "pdf[\"loc_hcm\"] = (pdf[\"ds_location\"] == \"Ho Chi Minh City\").astype(int)\n",
    "pdf[\"loc_dn\"] = (pdf[\"ds_location\"] == \"Da Nang City\").astype(int)\n",
    "pdf[\"loc_hn\"] = (pdf[\"ds_location\"] == \"Ha Noi City\").astype(int)\n",
    "\n",
    "# 2. Tái tạo Lags\n",
    "print(f\"Đang tạo {N_LAG_DAYS} ngày lags...\")\n",
    "lag_dfs = []\n",
    "for lag in range(1, N_LAG_DAYS + 1):\n",
    "    lag_df = pdf.groupby(\"ds_location\")[numeric_cols].shift(lag)\n",
    "    lag_df.columns = [f\"{c}_lag_{lag}\" for c in numeric_cols]\n",
    "    lag_dfs.append(lag_df)\n",
    "\n",
    "pdf = pd.concat([pdf] + lag_dfs, axis=1)\n",
    "pdf = pdf.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3. Định nghĩa Feature Columns\n",
    "# (FIX 2) Bao gồm cả 8 cột gốc (lag 0)\n",
    "numeric_feature_cols = [c for c in pdf.columns if any(x in c for x in numeric_cols)]\n",
    "feature_cols = numeric_feature_cols + location_cols\n",
    "\n",
    "print(f\"Đã tạo xong {len(feature_cols)} features (bao gồm 8 cột gốc + 192 cột lag + 3 cột location).\")\n",
    "\n",
    "# === CELL 6: DỰ BÁO VÀ LƯU KẾT QUẢ ===\n",
    "print(\"\\n--- Cell 6: Thực hiện Dự báo và Lưu kết quả ---\")\n",
    "\n",
    "all_forecasts = []\n",
    "today_run_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "forecast_date = pdf[\"dt_date_record\"].max() + pd.Timedelta(days=1)\n",
    "\n",
    "\n",
    "for city_name, loc_col in CITY_LOC_COLS.items():\n",
    "    print(f\"\\n--- Đang xử lý cho: {city_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        city_pdf = pdf[pdf[\"ds_location\"] == city_name].copy()\n",
    "        input_data = city_pdf.tail(SEQ_LEN)[feature_cols]\n",
    "        \n",
    "        if input_data.shape[0] != SEQ_LEN:\n",
    "            print(f\"LỖI: Không đủ dữ liệu (cần {SEQ_LEN} ngày) để dự báo cho {city_name}. Bỏ qua...\")\n",
    "            continue\n",
    "        \n",
    "        # (FIX 3) Ép kiểu dữ liệu để khớp với Signature\n",
    "        try:\n",
    "            for col_name in location_cols:\n",
    "                input_data[col_name] = input_data[col_name].astype(np.int32)\n",
    "            \n",
    "            for col_name in numeric_feature_cols:\n",
    "                input_data[col_name] = input_data[col_name].astype(np.float32)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"LỖI khi ép kiểu dữ liệu: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Gọi mô hình\n",
    "        print(f\"Đang dự báo cho {city_name}...\")\n",
    "        forecast_result_df = loaded_model.predict(input_data)\n",
    "        \n",
    "        forecast_result_df['dt_forecast_date'] = forecast_date\n",
    "        forecast_result_df['ds_location'] = city_name\n",
    "        forecast_result_df['dt_model_run_time'] = today_run_time\n",
    "        forecast_result_df['ds_model_version_uri'] = model_uri\n",
    "        \n",
    "        all_forecasts.append(forecast_result_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"LỖI trong quá trình xử lý cho {city_name}: {e}\")\n",
    "\n",
    "# (Lưu kết quả)\n",
    "if not all_forecasts:\n",
    "    print(\"\\nKhông có kết quả dự báo nào được tạo ra. Kết thúc.\")\n",
    "else:\n",
    "    print(f\"\\n--- TỔNG HỢP KẾT QUẢ DỰ BÁO ({len(all_forecasts)} thành phố) ---\")\n",
    "    final_results_df = pd.concat(all_forecasts)\n",
    "    display(final_results_df)\n",
    "\n",
    "    print(f\"Đang lưu tất cả kết quả vào bảng {TARGET_TABLE}...\")\n",
    "    \n",
    "    try:\n",
    "        results_spark_df = spark.createDataFrame(final_results_df)\n",
    "        (results_spark_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"append\")\n",
    "            .option(\"mergeSchema\", \"true\") \n",
    "            .saveAsTable(TARGET_TABLE)\n",
    "        )\n",
    "        print(\"--- LƯU KẾT QUẢ VÀO DELTA LAKE THÀNH CÔNG ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"LỖI khi lưu vào Delta Lake: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "predict_rain_lstm",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
